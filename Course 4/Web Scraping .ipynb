{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1356a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "     ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
      "     ---------- ---------------------------- 30.7/112.2 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------- ---------------------------- 30.7/112.2 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------- ----------------------- 41.0/112.2 kB 487.6 kB/s eta 0:00:01\n",
      "     ------------- ----------------------- 41.0/112.2 kB 487.6 kB/s eta 0:00:01\n",
      "     ------------- ----------------------- 41.0/112.2 kB 487.6 kB/s eta 0:00:01\n",
      "     ------------- ----------------------- 41.0/112.2 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------- ---------------- 61.4/112.2 kB 252.2 kB/s eta 0:00:01\n",
      "     -------------------- ---------------- 61.4/112.2 kB 252.2 kB/s eta 0:00:01\n",
      "     ----------------------- ------------- 71.7/112.2 kB 206.9 kB/s eta 0:00:01\n",
      "     ----------------------- ------------- 71.7/112.2 kB 206.9 kB/s eta 0:00:01\n",
      "     ------------------------------ ------ 92.2/112.2 kB 218.5 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 102.4/112.2 kB 218.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 112.2/112.2 kB 217.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hp\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d836a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.4)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1264 sha256=24f05b9eae4628b7dcfd6be7022b4a81aa68767b8d2c4db076d27314961fe29d\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\d4\\c8\\5b\\b5be9c20e5e4503d04a6eac8a3cd5c2393505c29f02bea0960\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "# installing beautiful soup for html web scraping\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbec2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232c7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing html as a variable\n",
    "\n",
    "html=\"<!DOCTYPE html><html><head><title>Page Title</title></head><body><h3><b id='boldest'>Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body></html>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed26a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To parse a document, pass it into the BeautifulSoup constructor.The BeautifulSoup object represents the document\n",
    "# as a nested data structure\n",
    "\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ffa8e",
   "metadata": {},
   "source": [
    "First, the document is converted to Unicode (similar to ASCII) and HTML entities are converted to Unicode characters. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. The BeautifulSoup object can create other types of objects. In this lab, we will cover BeautifulSoup and Tag objects, that for the purposes of this lab are identical. Finally, we will look at NavigableString objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820be446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Page Title\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h3>\n",
      "   <b id=\"boldest\">\n",
      "    Lebron James\n",
      "   </b>\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $ 92,000,000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Stephen Curry\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $85,000, 000\n",
      "  </p>\n",
      "  <h3>\n",
      "   Kevin Durant\n",
      "  </h3>\n",
      "  <p>\n",
      "   Salary: $73,200, 000\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can use the method prettify() to display the HTML in the nested structure:\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc1c14",
   "metadata": {},
   "source": [
    "# Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c2407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag object: <title>Page Title</title>\n"
     ]
    }
   ],
   "source": [
    "# Let's say we want the title of the page and the name of the top paid player. We can use the Tag.\n",
    "# The Tag object corresponds to an HTML tag in the original document, for example, the tag title.\n",
    "\n",
    "tag_object=soup.title\n",
    "print(\"tag object:\",tag_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4d766d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag object type: <class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "# Tag type\n",
    "\n",
    "print(\"tag object type:\",type(tag_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6995e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Lebron James</b></h3>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If there is more than one Tag with the same name, the first element with that Tag name is called.\n",
    "# This corresponds to the most paid player:\n",
    "\n",
    "tag_object = soup.h3\n",
    "tag_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ace5b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b id=\"boldest\">Lebron James</b>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can access the child of the tag or navigate down the branch as follows:\n",
    "\n",
    "tag_child =tag_object.b\n",
    "tag_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4731965d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3><b id=\"boldest\">Lebron James</b></h3>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can access the parent with the  parent\n",
    "\n",
    "parent_tag=tag_child.parent\n",
    "parent_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd685818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><h3><b id=\"boldest\">Lebron James</b></h3><p> Salary: $ 92,000,000 </p><h3> Stephen Curry</h3><p> Salary: $85,000, 000 </p><h3> Kevin Durant </h3><p> Salary: $73,200, 000</p></body>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag_object parent is the body element\n",
    "\n",
    "tag_object.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9308f087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p> Salary: $ 92,000,000 </p>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag_object sibling is the paragraph element\n",
    "\n",
    "sibling_1=tag_object.next_sibling\n",
    "sibling_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e42fbfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3> Stephen Curry</h3>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sibling_2 is the header element, which is also a sibling of both sibling_1 and tag_object\n",
    "\n",
    "sibling_2 = sibling_1.next_sibling\n",
    "sibling_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a4bc4",
   "metadata": {},
   "source": [
    "# Html Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e86d570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boldest'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the tag has attributes, the tag id=\"boldest\" has an attribute id whose value is boldest.\n",
    "# You can access a tag's attributes by treating the tag like a dictionary:\n",
    "\n",
    "tag_child['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36996de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'boldest'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dictionary directly as attrs(attributes)\n",
    "\n",
    "tag_child.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6574232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boldest'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also obtain the content of the attribute of the tag using the Python get() method\n",
    "\n",
    "tag_child.get('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c126776",
   "metadata": {},
   "source": [
    "# Navigable String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff26ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lebron James'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A string corresponds to a bit of text or content within a tag. \n",
    "# Beautiful Soup uses the NavigableString class to contain this text. \n",
    "# In our HTML we can obtain the name of the first player by extracting the string of the Tag object tag_child as follows:\n",
    "\n",
    "tag_string=tag_child.string\n",
    "tag_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca2aae15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lebron James'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A NavigableString is similar to a Python string or Unicode string. \n",
    "# To be more precise, the main difference is that it also supports some BeautifulSoup features.\n",
    "# We can convert it to string object in Python:\n",
    "\n",
    "unicode_string = str(tag_string)\n",
    "unicode_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a588484f",
   "metadata": {},
   "source": [
    "# Filter\n",
    "\n",
    "Filters allow you to find complex patterns, the simplest filter is a string. In this section we will pass a string to a different filter method and Beautiful Soup will perform a match against that exact string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a529595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=\"<table><tr><td id='flight'>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a></td><td>300 kg</td></tr><tr><td>2</td><td><a href='https://en.wikipedia.org/wiki/Texas'>Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href='https://en.wikipedia.org/wiki/Florida'>Florida<a> </td><td>80 kg</td></tr></table>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d08e9e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head></head><body><table><tbody><tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr><tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr><tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr></tbody></table></body></html>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs = BeautifulSoup(table, 'html5lib')\n",
    "table_bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2702e2e",
   "metadata": {},
   "source": [
    "# Find All\n",
    "The find_all() method looks through a tag's descendants and retrieves all descendants that match your filters.The Method signature for find_all(name, attrs, recursive, string, limit, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5bcea7",
   "metadata": {},
   "source": [
    "### Name\n",
    "When we set the name parameter to a tag name, the method will extract all the tags with that name and its children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ebf2483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n",
       " <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The find_all() method is used to find all the elements in a soup object that match a certain criteria. \n",
    "# In this case, the criteria is the <tr> tag.\n",
    "\n",
    "table_rows=table_bs.find_all('tr')\n",
    "table_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a97d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this assigns the first_row to find the first row of the variable table_rows \n",
    "\n",
    "first_row = table_rows[0]\n",
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53ffb9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td id=\"flight\">Flight No</td>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row.td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b5d4c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 is <tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>\n",
      "row 1 is <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>\n",
      "row 2 is <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>\n",
      "row 3 is <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>\n"
     ]
    }
   ],
   "source": [
    "# If we iterate through the list each element corresponds to a row in the table\n",
    "\n",
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i,\"is\",row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4438357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0\n",
      "colunm 0 cell <td id=\"flight\">Flight No</td>\n",
      "colunm 1 cell <td>Launch site</td>\n",
      "colunm 2 cell <td>Payload mass</td>\n",
      "row 1\n",
      "colunm 0 cell <td>1</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>\n",
      "colunm 2 cell <td>300 kg</td>\n",
      "row 2\n",
      "colunm 0 cell <td>2</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>\n",
      "colunm 2 cell <td>94 kg</td>\n",
      "row 3\n",
      "colunm 0 cell <td>3</td>\n",
      "colunm 1 cell <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>\n",
      "colunm 2 cell <td>80 kg</td>\n"
     ]
    }
   ],
   "source": [
    "# getting each td in the column tr \n",
    "\n",
    "for i,row in enumerate(table_rows):\n",
    "    print(\"row\",i)\n",
    "    cells=row.find_all('td')\n",
    "    for j,cell in enumerate(cells):\n",
    "        print('colunm',j,\"cell\",cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3e6b8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td id=\"flight\">Flight No</td><td>Launch site</td> <td>Payload mass</td></tr>,\n",
       " <td id=\"flight\">Flight No</td>,\n",
       " <td>Launch site</td>,\n",
       " <td>Payload mass</td>,\n",
       " <tr> <td>1</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td><td>300 kg</td></tr>,\n",
       " <td>1</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a></a></td>,\n",
       " <td>300 kg</td>,\n",
       " <tr><td>2</td><td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td><td>94 kg</td></tr>,\n",
       " <td>2</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a></td>,\n",
       " <td>94 kg</td>,\n",
       " <tr><td>3</td><td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td><td>80 kg</td></tr>,\n",
       " <td>3</td>,\n",
       " <td><a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a><a> </a></td>,\n",
       " <td>80 kg</td>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input=table_bs .find_all(name=[\"tr\", \"td\"])\n",
    "list_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bde115",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "230258c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td id=\"flight\">Flight No</td>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(id=\"flight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f584bf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can find all pics related to florida\n",
    "\n",
    "list_input=table_bs.find_all(href=\"https://en.wikipedia.org/wiki/Florida\")\n",
    "list_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a86053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Texas\">Texas</a>,\n",
       " <a href=\"https://en.wikipedia.org/wiki/Florida\">Florida</a>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we set the href attribute to True, regardless of what the value is, the code finds all tags with href value:\n",
    "table_bs.find_all(href = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee9f210a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Florida', 'Florida']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_bs.find_all(string=\"Florida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b56c3",
   "metadata": {},
   "source": [
    "### Find\n",
    "The find_all() method scans the entire document looking for results. It’s useful if you are looking for one element, as you can use the find() method to find the first element in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09cffda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_tables=\"<h3>Rocket Launch </h3><p><table class='rocket'><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table></p><p><h3>Pizza Party  </h3><table class='pizza'><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td >144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4387af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a beautifulshop object two_tables_bs\n",
    "\n",
    "two_tables_bs= BeautifulSoup(two_tables, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51f0292e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"rocket\"><tr><td>Flight No</td><td>Launch site</td> <td>Payload mass</td></tr><tr><td>1</td><td>Florida</td><td>300 kg</td></tr><tr><td>2</td><td>Texas</td><td>94 kg</td></tr><tr><td>3</td><td>Florida </td><td>80 kg</td></tr></table>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the first table using the tag name table\n",
    "\n",
    "two_tables_bs.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7267445f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table class=\"pizza\"><tr><td>Pizza Place</td><td>Orders</td> <td>Slices </td></tr><tr><td>Domino's Pizza</td><td>10</td><td>100</td></tr><tr><td>Little Caesars</td><td>12</td><td>144 </td></tr><tr><td>Papa John's </td><td>15 </td><td>165</td></tr></table>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the table where the class is pizza\n",
    "\n",
    "two_tables_bs.find(\"table\",class_='pizza')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcfdac0",
   "metadata": {},
   "source": [
    "# Downloading And Scraping The Contents Of A Web Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d72ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We Download the contents of the web page:\n",
    "\n",
    "url = \"http://www.ibm.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b038419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use get to download the contents of the webpage in text format and store in a variable called data\n",
    "\n",
    "data  = requests.get(url).text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2524c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a soup object using the variable 'data'\n",
    "\n",
    "soup = BeautifulSoup(data,\"html5lib\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68013c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://newsroom.ibm.com/2023-08-10-IBM-Completes-Acquisition-of-Apptio-Inc\n",
      "https://www.ibm.com/community/ibm-techxchange-conference\n",
      "https://www.ibm.com/products/watsonx-ai\n",
      "https://www.ibm.com/products/watsonx-data\n",
      "https://www.ibm.com/products/spss-statistics/pricing\n",
      "https://www.ibm.com/sports/usopen\n",
      "https://www.ibm.com/cloud?lnk=flatitem\n",
      "https://www.ibm.com/products\n",
      "https://www.ibm.com/consulting\n",
      "https://www.ibm.com/about\n",
      "https://www.ibm.com/\n"
     ]
    }
   ],
   "source": [
    "# Scrape all links\n",
    "# in html anchor/link is represented by the tag <a>\n",
    "# The find_all() method is used to find all the elements in a soup object that match a certain criteria. \n",
    "# In this case, the criteria is the 'a' tag\n",
    "\n",
    "for link in soup.find_all('a',href=True):  \n",
    "    print(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1013279",
   "metadata": {},
   "source": [
    "### Scrape all images Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48a3aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Tennis player returns serve in Wimbledon stadium\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0c627169442d5243/ibm_watsonx_data_closeup_still_4k.jpg.global.sr_1x1.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0c627169442d5243/ibm_watsonx_data_closeup_still_4k.jpg.global.sr_1x1.jpg\n",
      "<img alt=\"Concentric illustration showing watsonx.ai capabilities\" aria-describedby=\"bx--image-3\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0c3ce2dfcccd1f24/watsonx-data-square.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0c3ce2dfcccd1f24/watsonx-data-square.jpg\n",
      "<img alt=\"Illustration of workers digital planning with blue dots and post-its\" aria-describedby=\"bx--image-4\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0c3ce2dfcccd1f25/watsonx-ai-square.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0c3ce2dfcccd1f25/watsonx-ai-square.jpg\n",
      "<img alt=\"Illustration of people at large digital dashboard\" aria-describedby=\"bx--image-5\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0b5258b292cc8c3c/ibm-SPSS-home-card.png.global.xs_1x1.png\"/>\n",
      "https://1.dam.s81c.com/p/0b5258b292cc8c3c/ibm-SPSS-home-card.png.global.xs_1x1.png\n",
      "<img alt=\"Aerial view of crowded Arthur Ashe Stadium during the US Open\" aria-describedby=\"bx--image-6\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0b5208b4cbcc2792/MikeLawrenceUSTA.jpg.global.xs_1x1.png\"/>\n",
      "https://1.dam.s81c.com/p/0b5208b4cbcc2792/MikeLawrenceUSTA.jpg.global.xs_1x1.png\n",
      "<img alt=\"Grid of IBM consultant portraits\" class=\"bx--image__img\" src=\"https://1.dam.s81c.com/p/0aac9cf57bcbf324/dotcom-1-overview.jpg\"/>\n",
      "https://1.dam.s81c.com/p/0aac9cf57bcbf324/dotcom-1-overview.jpg\n"
     ]
    }
   ],
   "source": [
    "# in html image is represented by the tag <img>\n",
    "# the html is first printed\n",
    "# the link which is contained within the 'src' is then printed\n",
    "\n",
    "for link in soup.find_all('img'):\n",
    "    print(link)\n",
    "    print(link.get('src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe437c5",
   "metadata": {},
   "source": [
    "### Scrape data from HTML tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef6a7dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below url contains an html table with data about colors and color codes.\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0eb76200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Before proceeding to scrape a web site, you need to examine the contents and the way data is organized on the website. \n",
    "# Open the above url in your browser and check how many rows and columns there are in the color table.\n",
    "\n",
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data1  = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fc30c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data,\"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8efa0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find a html table in the web page\n",
    "# in html table is represented by the tag <table>\n",
    "\n",
    "table = soup.find('table') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7f332844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Name--->Hex Code#RRGGBB\n",
      "lightsalmon--->#FFA07A\n",
      "salmon--->#FA8072\n",
      "darksalmon--->#E9967A\n",
      "lightcoral--->#F08080\n",
      "coral--->#FF7F50\n",
      "tomato--->#FF6347\n",
      "orangered--->#FF4500\n",
      "gold--->#FFD700\n",
      "orange--->#FFA500\n",
      "darkorange--->#FF8C00\n",
      "lightyellow--->#FFFFE0\n",
      "lemonchiffon--->#FFFACD\n",
      "papayawhip--->#FFEFD5\n",
      "moccasin--->#FFE4B5\n",
      "peachpuff--->#FFDAB9\n",
      "palegoldenrod--->#EEE8AA\n",
      "khaki--->#F0E68C\n",
      "darkkhaki--->#BDB76B\n",
      "yellow--->#FFFF00\n",
      "lawngreen--->#7CFC00\n",
      "chartreuse--->#7FFF00\n",
      "limegreen--->#32CD32\n",
      "lime--->#00FF00\n",
      "forestgreen--->#228B22\n",
      "green--->#008000\n",
      "powderblue--->#B0E0E6\n",
      "lightblue--->#ADD8E6\n",
      "lightskyblue--->#87CEFA\n",
      "skyblue--->#87CEEB\n",
      "deepskyblue--->#00BFFF\n",
      "lightsteelblue--->#B0C4DE\n",
      "dodgerblue--->#1E90FF\n"
     ]
    }
   ],
   "source": [
    "#Get all rows from the table\n",
    "for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n",
    "    # Get all columns in each row.\n",
    "    cols = row.find_all('td') # in html a column is represented by the tag <td>\n",
    "    color_name = cols[2].string # store the value in column 3 as color_name\n",
    "    color_code = cols[3].text # store the value in column 4 as color_code\n",
    "    print(\"{}--->{}\".format(color_name,color_code))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff92ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
